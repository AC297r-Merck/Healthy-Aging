{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying with healthy CpGs\n",
    "\n",
    "- This workbook contains the classification models for healthy vs Alzheimer's vs Huntingtons using the HC top 55 CpG sites and the HC linear model residual values\n",
    "\n",
    "- 3 classifiers:\n",
    "\n",
    "1. Using top 55 CpGs and age to classify Healthy vs Huntingtons vs Alzheimers\n",
    "2. Using top 55 CpGs and age to classify Healthy vs Alzheimers\n",
    "3. Using linear model residual values and age to classify Healthy vs Alzheimers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as cPickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from math import sqrt\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "huntingtons_df=pd.read_csv('../huntingtons/hunt_brain_top_55.csv',index_col=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alzheimers_df=pd.read_csv('../alzheimers/alz_brain_top_55.csv',index_col=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop ages outside range 20-100\n",
    "huntingtons_df=huntingtons_df.loc[huntingtons_df['AGE'] >= 20]\n",
    "huntingtons_df=huntingtons_df.loc[huntingtons_df['AGE'] <= 110]\n",
    "alzheimers_df=alzheimers_df.loc[alzheimers_df['AGE'] >= 20]\n",
    "alzheimers_df=alzheimers_df.loc[alzheimers_df['AGE'] <= 110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy=pd.read_csv('../healthy/hc_brain_55CpGs.csv',index_col=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop ages outside range 20-100\n",
    "healthy=healthy.loc[healthy['age'] >= 20]\n",
    "healthy=healthy.loc[healthy['age'] <= 110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get any CpGs in healthy dataframe that are not in brain_shared_healthy_unhealthy file and print\n",
    "#un=list(hc_df.columns)[1:]\n",
    "#alz=list(alzheimers_df.columns)[1:]\n",
    "\n",
    "#with open(r\"../brain_shared_healthy_unhealthy\", \"rb\") as input_file:\n",
    "    #brain_shared_healthy_unhealthy = cPickle.load(input_file)\n",
    "    \n",
    "#brain_shared_healthy_unhealthy=list(brain_shared_healthy_unhealthy)\n",
    "#for i in un:\n",
    "    #if i not in alz:\n",
    "        #print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy=healthy.drop(columns=['cg00050873'])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding status column\n",
    "\n",
    "Healthy = 0\n",
    "\n",
    "Alzheimer's = 1\n",
    "\n",
    "Huntingston's = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy['status']=[0]*len(list(healthy.index))\n",
    "alzheimers_df['status']=[1]*len(list(alzheimers_df.index))\n",
    "huntingtons_df['status']=[2]*len(list(huntingtons_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy=healthy.rename(columns={\"age\": \"AGE\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy=healthy[['status', 'AGE']+list(healthy.columns)[1:-1]]\n",
    "alzheimers_df=alzheimers_df[['status', 'AGE']+list(alzheimers_df.columns)[1:-1]]\n",
    "huntingtons_df=huntingtons_df[['status', 'AGE']+list(huntingtons_df.columns)[1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>AGE</th>\n",
       "      <th>cg00807959</th>\n",
       "      <th>cg01066472</th>\n",
       "      <th>cg13806070</th>\n",
       "      <th>cg15907146</th>\n",
       "      <th>cg17104258</th>\n",
       "      <th>cg24441324</th>\n",
       "      <th>cg22454769</th>\n",
       "      <th>cg23606718</th>\n",
       "      <th>...</th>\n",
       "      <th>cg19622662</th>\n",
       "      <th>cg23595055</th>\n",
       "      <th>cg04739123</th>\n",
       "      <th>cg16367511</th>\n",
       "      <th>cg18008766</th>\n",
       "      <th>cg19451698</th>\n",
       "      <th>cg04834794</th>\n",
       "      <th>cg07303143</th>\n",
       "      <th>cg21182694</th>\n",
       "      <th>cg23352942</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSM2139432</th>\n",
       "      <td>0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM2139249</th>\n",
       "      <td>0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM2139398</th>\n",
       "      <td>0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM2139297</th>\n",
       "      <td>0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1069208</th>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1871815</th>\n",
       "      <td>2</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1871849</th>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1871852</th>\n",
       "      <td>2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1871860</th>\n",
       "      <td>2</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1871861</th>\n",
       "      <td>2</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2311 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            status    AGE  cg00807959  cg01066472  cg13806070  cg15907146  \\\n",
       "GSM2139432       0   71.0       0.288       0.331       0.128       0.607   \n",
       "GSM2139249       0   76.0       0.329       0.378       0.140       0.563   \n",
       "GSM2139398       0  102.0       0.294       0.339       0.067       0.604   \n",
       "GSM2139297       0  108.0       0.327       0.528       0.153       0.703   \n",
       "GSM1069208       0   40.0       0.152       0.452       0.056       0.559   \n",
       "...            ...    ...         ...         ...         ...         ...   \n",
       "GSM1871815       2   56.0       0.231       0.244       0.117       0.587   \n",
       "GSM1871849       2   62.0       0.212       0.433       0.125       0.667   \n",
       "GSM1871852       2   58.0       0.250       0.449       0.120       0.623   \n",
       "GSM1871860       2   91.0       0.287       0.657       0.129       0.649   \n",
       "GSM1871861       2   45.0       0.204       0.529       0.125       0.569   \n",
       "\n",
       "            cg17104258  cg24441324  cg22454769  cg23606718  ...  cg19622662  \\\n",
       "GSM2139432       0.106       0.829       0.299       0.158  ...       0.088   \n",
       "GSM2139249       0.101       0.880       0.413       0.153  ...       0.095   \n",
       "GSM2139398       0.188       0.824       0.395       0.121  ...       0.154   \n",
       "GSM2139297       0.054       0.847       0.438       0.262  ...       0.053   \n",
       "GSM1069208       0.250       0.840       0.212       0.085  ...       0.232   \n",
       "...                ...         ...         ...         ...  ...         ...   \n",
       "GSM1871815       0.175       0.919       0.265       0.140  ...       0.077   \n",
       "GSM1871849       0.044       0.845       0.155       0.147  ...       0.062   \n",
       "GSM1871852       0.212       0.917       0.273       0.130  ...       0.159   \n",
       "GSM1871860       0.017       0.902       0.324       0.176  ...       0.055   \n",
       "GSM1871861       0.242       0.864       0.178       0.127  ...       0.223   \n",
       "\n",
       "            cg23595055  cg04739123  cg16367511  cg18008766  cg19451698  \\\n",
       "GSM2139432       0.948       0.037       0.217       0.105       0.102   \n",
       "GSM2139249       0.942       0.039       0.161       0.130       0.064   \n",
       "GSM2139398       0.947       0.044       0.124       0.114       0.085   \n",
       "GSM2139297       0.964       0.088       0.261       0.168       0.105   \n",
       "GSM1069208       0.898       0.038       0.083       0.073       0.044   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "GSM1871815       0.959       0.048       0.112       0.052       0.038   \n",
       "GSM1871849       0.969       0.049       0.141       0.066       0.044   \n",
       "GSM1871852       0.935       0.035       0.141       0.069       0.048   \n",
       "GSM1871860       0.983       0.052       0.154       0.069       0.060   \n",
       "GSM1871861       0.926       0.024       0.092       0.050       0.041   \n",
       "\n",
       "            cg04834794  cg07303143  cg21182694  cg23352942  \n",
       "GSM2139432       0.124       0.289       0.240       0.475  \n",
       "GSM2139249       0.084       0.318       0.215       0.466  \n",
       "GSM2139398       0.063       0.317       0.219       0.432  \n",
       "GSM2139297       0.192       0.419       0.293       0.559  \n",
       "GSM1069208       0.023       0.231       0.193       0.602  \n",
       "...                ...         ...         ...         ...  \n",
       "GSM1871815       0.025       0.161       0.181       0.425  \n",
       "GSM1871849       0.063       0.205       0.211       0.420  \n",
       "GSM1871852       0.043       0.233       0.176       0.496  \n",
       "GSM1871860       0.057       0.276       0.237       0.384  \n",
       "GSM1871861       0.044       0.215       0.232       0.491  \n",
       "\n",
       "[2311 rows x 57 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames=[healthy,alzheimers_df,huntingtons_df]\n",
    "classification_df = pd.concat(frames)\n",
    "classification_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_impute(data):\n",
    "    nas=data.isnull().sum()    \n",
    "    col_means=data.mean(axis=0)\n",
    "    na_cols=[]\n",
    "    na_cols_means=[]\n",
    "\n",
    "    for i in range(len(nas)):\n",
    "        if nas[i]!=0:        \n",
    "            na_cols.append(nas.keys()[i])\n",
    "            na_cols_means.append(col_means[i])\n",
    "        \n",
    "    ids=list(data.index)\n",
    "    for i in ids:\n",
    "        for j in range(len(na_cols)):\n",
    "            if str(data.loc[i][na_cols[j]])==\"nan\":\n",
    "                data.loc[i][na_cols[j]]=na_cols_means[j]\n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying healthy vs Alzheimer's vs Huntington's\n",
    "\n",
    "- Using top 55 CpGs from HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in test/train split IDs\n",
    "with open(r\"../train_test_ids/brain_alz_working_ids\", \"rb\") as input_file:\n",
    "    brain_alz_working_ids = cPickle.load(input_file)\n",
    "with open(r\"../train_test_ids/brain_alz_held_out_ids\", \"rb\") as input_file:\n",
    "    brain_alz_held_out_ids = cPickle.load(input_file)\n",
    "\n",
    "with open(r\"../train_test_ids/brain_hunt_working_ids\", \"rb\") as input_file:\n",
    "    brain_hunt_working_ids = cPickle.load(input_file)\n",
    "with open(r\"../train_test_ids/brain_hunt_held_out_ids\", \"rb\") as input_file:\n",
    "    brain_hunt_held_out_ids = cPickle.load(input_file)\n",
    "\n",
    "#Reading in test/train split IDs for healthy \n",
    "with open(r\"../train_test_ids/brain_working_sample_ids\", \"rb\") as input_file:\n",
    "    brain_hc_working_ids = cPickle.load(input_file)\n",
    "with open(r\"../train_test_ids/brain_saved_sample_ids\", \"rb\") as input_file:\n",
    "    brain_hc_held_out_ids = cPickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting working and heldout dataframes \n",
    "classification_df_working=classification_df\n",
    "classification_df_heldout=classification_df\n",
    "all_id=list(classification_df.index)\n",
    "for i in all_id:\n",
    "    if i not in brain_alz_working_ids and i not in brain_hc_working_ids and i not in brain_hunt_working_ids:\n",
    "        classification_df_working=classification_df_working.drop([i])\n",
    "    if i not in brain_alz_held_out_ids and i not in brain_hc_held_out_ids and i not in brain_hunt_held_out_ids:\n",
    "        classification_df_heldout=classification_df_heldout.drop([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X and y split for working and held out data\n",
    "X_hold=classification_df_heldout.iloc[:,1:]\n",
    "y_hold=classification_df_heldout.iloc[:,0]\n",
    "X_hold=mean_impute(X_hold)\n",
    "X_work=classification_df_working.iloc[:,1:]\n",
    "y_work=classification_df_working.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_tst, y_train, y_test = train_test_split(X_work, y_work, test_size=0.25,random_state=4)\n",
    "X_train = mean_impute(X_tr)\n",
    "X_test = mean_impute(X_tst)\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train,y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define class accuracy function\n",
    "def class_accuracy(true,pred):\n",
    "    correct=0\n",
    "    total=len(pred)\n",
    "    for i in range(total):\n",
    "        if pred[i]==true[i]:\n",
    "            correct+=1\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc =  0.6674382716049383  Test acc =  0.7205542725173211\n",
      "Heldout data acc =  0.6683848797250859\n",
      "Classification report test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.72      0.82      0.77       237\n",
      "  Alzheimers       0.74      0.73      0.74       146\n",
      " Huntingtons       0.59      0.20      0.30        50\n",
      "\n",
      "    accuracy                           0.72       433\n",
      "   macro avg       0.68      0.59      0.60       433\n",
      "weighted avg       0.71      0.72      0.70       433\n",
      "\n",
      "Classification held out data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.71      0.74      0.72       319\n",
      "  Alzheimers       0.62      0.70      0.66       196\n",
      " Huntingtons       0.58      0.22      0.32        67\n",
      "\n",
      "    accuracy                           0.67       582\n",
      "   macro avg       0.64      0.56      0.57       582\n",
      "weighted avg       0.66      0.67      0.66       582\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "train_acc = class_accuracy(y_train,y_train_pred)\n",
    "test_acc = class_accuracy(y_test,y_test_pred)\n",
    "print('Train acc = ',train_acc,' Test acc = ',test_acc)\n",
    "y_hold_pred = model.predict(X_hold)\n",
    "valid_acc = class_accuracy(y_hold,y_hold_pred)\n",
    "print('Heldout data acc = ',valid_acc)\n",
    "print('Classification report test')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Healthy','Alzheimers','Huntingtons']))\n",
    "print('Classification held out data')\n",
    "print(classification_report(y_hold,y_hold_pred,target_names=['Healthy','Alzheimers','Huntingtons']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying healthy vs Alzheimer's \n",
    "\n",
    "- Using top 55 CpGs from HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames2=[healthy,alzheimers_df]\n",
    "alzheimers_classification_df = pd.concat(frames2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting working and heldout dataframes \n",
    "alzheimers_classification_df_working=alzheimers_classification_df\n",
    "alzheimers_classification_df_heldout=alzheimers_classification_df\n",
    "all_alz_class_id=list(alzheimers_classification_df.index)\n",
    "for i in all_alz_class_id:\n",
    "    if i not in brain_alz_working_ids and i not in brain_hc_working_ids:\n",
    "        alzheimers_classification_df_working=alzheimers_classification_df_working.drop([i])\n",
    "    if i not in brain_alz_held_out_ids and i not in brain_hc_held_out_ids:\n",
    "        alzheimers_classification_df_heldout=alzheimers_classification_df_heldout.drop([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X and y split for working and held out data\n",
    "X_hold=alzheimers_classification_df_heldout.iloc[:,1:]\n",
    "y_hold=alzheimers_classification_df_heldout.iloc[:,0]\n",
    "X_hold=mean_impute(X_hold)\n",
    "X_work=alzheimers_classification_df_working.iloc[:,1:]\n",
    "y_work=alzheimers_classification_df_working.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_tst, y_train, y_test = train_test_split(X_work, y_work, test_size=0.25,random_state=4)\n",
    "X_train = mean_impute(X_tr)\n",
    "X_test = mean_impute(X_tst)\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train,y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc =  0.7364746945898778  Test acc =  0.7597911227154047\n",
      "Heldout data acc =  0.7203883495145631\n",
      "Classification report test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.79      0.82      0.81       231\n",
      "  Alzheimers       0.71      0.66      0.69       152\n",
      "\n",
      "    accuracy                           0.76       383\n",
      "   macro avg       0.75      0.74      0.75       383\n",
      "weighted avg       0.76      0.76      0.76       383\n",
      "\n",
      "Classification held out data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.78      0.77      0.77       319\n",
      "  Alzheimers       0.63      0.64      0.64       196\n",
      "\n",
      "    accuracy                           0.72       515\n",
      "   macro avg       0.70      0.71      0.70       515\n",
      "weighted avg       0.72      0.72      0.72       515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "train_acc = class_accuracy(y_train,y_train_pred)\n",
    "test_acc = class_accuracy(y_test,y_test_pred)\n",
    "print('Train acc = ',train_acc,' Test acc = ',test_acc)\n",
    "y_hold_pred = model.predict(X_hold)\n",
    "valid_acc = class_accuracy(y_hold,y_hold_pred)\n",
    "print('Heldout data acc = ',valid_acc)\n",
    "print('Classification report test')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Healthy','Alzheimers']))\n",
    "print('Classification held out data')\n",
    "print(classification_report(y_hold,y_hold_pred,target_names=['Healthy','Alzheimers']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification healthy vs Alzheimers with residual values\n",
    "\n",
    "- Using HC's model residuals to classify healthy vs. Alzheimers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding residual values\n",
    "#Read in linear model\n",
    "mod_55_brain = pd.read_pickle(r'../models/brain_mod_55')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X and y split for working and held out data\n",
    "X_hold=alzheimers_classification_df_heldout.iloc[:,1:]\n",
    "y_hold=alzheimers_classification_df_heldout.iloc[:,0]\n",
    "X_hold=mean_impute(X_hold)\n",
    "\n",
    "X_work=alzheimers_classification_df_working.iloc[:,1:]\n",
    "X_work=mean_impute(X_work)\n",
    "y_work=alzheimers_classification_df_working.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_work = mod_55_brain.predict(X_work.iloc[:,1:])\n",
    "res_work=pred_work.reshape((1,pred_work.shape[0]))-X_work.iloc[:,0].values\n",
    "X_work['residuals']=res_work[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_hold = mod_55_brain.predict(X_hold.iloc[:,1:])\n",
    "res_hold=pred_hold.reshape((1,pred_hold.shape[0]))-X_hold.iloc[:,0].values\n",
    "X_hold['residuals']=res_hold[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>cg00807959</th>\n",
       "      <th>cg01066472</th>\n",
       "      <th>cg13806070</th>\n",
       "      <th>cg15907146</th>\n",
       "      <th>cg17104258</th>\n",
       "      <th>cg24441324</th>\n",
       "      <th>cg22454769</th>\n",
       "      <th>cg23606718</th>\n",
       "      <th>cg24079702</th>\n",
       "      <th>...</th>\n",
       "      <th>cg23595055</th>\n",
       "      <th>cg04739123</th>\n",
       "      <th>cg16367511</th>\n",
       "      <th>cg18008766</th>\n",
       "      <th>cg19451698</th>\n",
       "      <th>cg04834794</th>\n",
       "      <th>cg07303143</th>\n",
       "      <th>cg21182694</th>\n",
       "      <th>cg23352942</th>\n",
       "      <th>residuals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSM1443489</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.231000</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.602</td>\n",
       "      <td>66.617130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1069141</th>\n",
       "      <td>59.0</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.319000</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.485</td>\n",
       "      <td>68.393146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1069172</th>\n",
       "      <td>66.0</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.284000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.562</td>\n",
       "      <td>64.513223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1443533</th>\n",
       "      <td>66.0</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.284000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.562</td>\n",
       "      <td>64.513223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1443763</th>\n",
       "      <td>67.0</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.221000</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.475</td>\n",
       "      <td>52.932824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM2809047</th>\n",
       "      <td>76.0</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.222000</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.471</td>\n",
       "      <td>59.924888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM2809048</th>\n",
       "      <td>87.0</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.257352</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.417</td>\n",
       "      <td>57.471041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM2809053</th>\n",
       "      <td>78.0</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.257352</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.602</td>\n",
       "      <td>60.956629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM2809054</th>\n",
       "      <td>76.0</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.257352</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.503</td>\n",
       "      <td>59.363260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM2809061</th>\n",
       "      <td>70.0</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.257352</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.592</td>\n",
       "      <td>69.280067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>515 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AGE  cg00807959  cg01066472  cg13806070  cg15907146  cg17104258  \\\n",
       "GSM1443489  40.0       0.152       0.452       0.056       0.559       0.250   \n",
       "GSM1069141  59.0       0.254       0.358       0.118       0.580       0.096   \n",
       "GSM1069172  66.0       0.270       0.382       0.183       0.652       0.072   \n",
       "GSM1443533  66.0       0.270       0.382       0.183       0.652       0.072   \n",
       "GSM1443763  67.0       0.212       0.354       0.116       0.629       0.046   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "GSM2809047  76.0       0.316       0.495       0.152       0.670       0.155   \n",
       "GSM2809048  87.0       0.311       0.543       0.162       0.664       0.044   \n",
       "GSM2809053  78.0       0.313       0.622       0.148       0.708       0.144   \n",
       "GSM2809054  76.0       0.285       0.498       0.143       0.621       0.114   \n",
       "GSM2809061  70.0       0.366       0.520       0.118       0.554       0.394   \n",
       "\n",
       "            cg24441324  cg22454769  cg23606718  cg24079702  ...  cg23595055  \\\n",
       "GSM1443489       0.840       0.212       0.085       0.144  ...       0.898   \n",
       "GSM1069141       0.794       0.359       0.168       0.267  ...       0.981   \n",
       "GSM1069172       0.874       0.376       0.176       0.291  ...       0.955   \n",
       "GSM1443533       0.874       0.376       0.176       0.291  ...       0.955   \n",
       "GSM1443763       0.875       0.295       0.127       0.269  ...       0.962   \n",
       "...                ...         ...         ...         ...  ...         ...   \n",
       "GSM2809047       0.870       0.347       0.170       0.224  ...       0.926   \n",
       "GSM2809048       0.886       0.387       0.190       0.285  ...       0.941   \n",
       "GSM2809053       0.905       0.439       0.159       0.295  ...       0.946   \n",
       "GSM2809054       0.891       0.372       0.167       0.251  ...       0.948   \n",
       "GSM2809061       0.887       0.383       0.221       0.249  ...       0.910   \n",
       "\n",
       "            cg04739123  cg16367511  cg18008766  cg19451698  cg04834794  \\\n",
       "GSM1443489       0.038       0.083       0.073       0.044       0.023   \n",
       "GSM1069141       0.041       0.140       0.057       0.054       0.076   \n",
       "GSM1069172       0.047       0.136       0.097       0.099       0.033   \n",
       "GSM1443533       0.047       0.136       0.097       0.099       0.033   \n",
       "GSM1443763       0.053       0.135       0.081       0.061       0.091   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "GSM2809047       0.072       0.163       0.120       0.061       0.088   \n",
       "GSM2809048       0.074       0.184       0.108       0.054       0.077   \n",
       "GSM2809053       0.059       0.119       0.126       0.079       0.064   \n",
       "GSM2809054       0.084       0.155       0.095       0.099       0.100   \n",
       "GSM2809061       0.075       0.117       0.090       0.058       0.054   \n",
       "\n",
       "            cg07303143  cg21182694  cg23352942  residuals  \n",
       "GSM1443489    0.231000       0.193       0.602  66.617130  \n",
       "GSM1069141    0.319000       0.219       0.485  68.393146  \n",
       "GSM1069172    0.284000       0.232       0.562  64.513223  \n",
       "GSM1443533    0.284000       0.232       0.562  64.513223  \n",
       "GSM1443763    0.221000       0.198       0.475  52.932824  \n",
       "...                ...         ...         ...        ...  \n",
       "GSM2809047    0.222000       0.206       0.471  59.924888  \n",
       "GSM2809048    0.257352       0.307       0.417  57.471041  \n",
       "GSM2809053    0.257352       0.164       0.602  60.956629  \n",
       "GSM2809054    0.257352       0.207       0.503  59.363260  \n",
       "GSM2809061    0.257352       0.214       0.592  69.280067  \n",
       "\n",
       "[515 rows x 57 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hold=X_hold.iloc[:,[0,-1]]\n",
    "X_work=X_work.iloc[:,[0,-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working data test/train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_tst, y_train, y_test = train_test_split(X_work, y_work, test_size=0.25,random_state=4)\n",
    "X_train = mean_impute(X_tr)\n",
    "X_test = mean_impute(X_tst)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train,y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc =  0.7094240837696335  Test acc =  0.7519582245430809\n",
      "Heldout data acc =  0.6932038834951456\n",
      "Classification report test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.78      0.82      0.80       231\n",
      "  Alzheimers       0.71      0.64      0.67       152\n",
      "\n",
      "    accuracy                           0.75       383\n",
      "   macro avg       0.74      0.73      0.74       383\n",
      "weighted avg       0.75      0.75      0.75       383\n",
      "\n",
      "Classification held out data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.75      0.76      0.75       319\n",
      "  Alzheimers       0.60      0.59      0.59       196\n",
      "\n",
      "    accuracy                           0.69       515\n",
      "   macro avg       0.67      0.67      0.67       515\n",
      "weighted avg       0.69      0.69      0.69       515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "train_acc = class_accuracy(y_train,y_train_pred)\n",
    "test_acc = class_accuracy(y_test,y_test_pred)\n",
    "print('Train acc = ',train_acc,' Test acc = ',test_acc)\n",
    "y_hold_pred = model.predict(X_hold)\n",
    "valid_acc = class_accuracy(y_hold,y_hold_pred)\n",
    "print('Heldout data acc = ',valid_acc)\n",
    "print('Classification report test')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Healthy','Alzheimers']))\n",
    "print('Classification held out data')\n",
    "print(classification_report(y_hold,y_hold_pred,target_names=['Healthy','Alzheimers']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
