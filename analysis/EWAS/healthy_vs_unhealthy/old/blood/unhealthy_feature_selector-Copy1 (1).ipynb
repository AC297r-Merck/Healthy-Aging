{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost unhealthy feature selection\n",
    "\n",
    "- Parallel implementation of feature selection specifically for AWS\n",
    "- Each iteration is saved as you go along in case the kernel is interupted\n",
    "- All available cores are used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pillow==4.1.1\n",
      "  Downloading Pillow-4.1.1-cp36-cp36m-manylinux1_x86_64.whl (5.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.7 MB 14.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: olefile in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pillow==4.1.1) (0.46)\n",
      "Installing collected packages: pillow\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 7.2.0\n",
      "    Uninstalling Pillow-7.2.0:\n",
      "      Successfully uninstalled Pillow-7.2.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scikit-image 0.16.2 requires pillow>=4.3.0, but you have pillow 4.1.1 which is incompatible.\n",
      "matplotlib 3.3.4 requires pillow>=6.2.0, but you have pillow 4.1.1 which is incompatible.\n",
      "bokeh 2.2.3 requires pillow>=7.1.0, but you have pillow 4.1.1 which is incompatible.\u001b[0m\n",
      "Successfully installed pillow-4.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow==4.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: \\ \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - conda-forge/noarch::imageio==2.9.0=py_0\n",
      "  - conda-forge/linux-64::jupyter_server==1.4.1=py36h5fab9bb_0\n",
      "  - conda-forge/noarch::black==20.8b1=py_1\n",
      "  - conda-forge/linux-64::bokeh==2.2.3=py36h5fab9bb_0\n",
      "  - defaults/linux-64::_anaconda_depends==5.1.0=py36_2\n",
      "  - conda-forge/noarch::pyls-black==0.4.6=pyh9f0ad1d_0\n",
      "  - conda-forge/noarch::aiobotocore==1.2.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pyls-spyder==0.3.2=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::anyio==2.1.0=py36h5fab9bb_0\n",
      "  - conda-forge/noarch::jupyterlab_server==2.3.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::matplotlib-base==3.3.4=py36hd391965_0\n",
      "  - conda-forge/linux-64::spyder==4.2.0=py36h5fab9bb_0\n",
      "  - conda-forge/noarch::python-language-server==0.36.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::seaborn-base==0.11.1=pyhd8ed1ab_1\n",
      "  - conda-forge/noarch::sphinx==3.5.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbclassic==0.2.6=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::yarl==1.6.3=py36h8f6f2f9_1\n",
      "  - conda-forge/linux-64::idna_ssl==1.1.0=py36h9f0ad1d_1001\n",
      "  - conda-forge/noarch::numpydoc==1.1.0=py_1\n",
      "  - conda-forge/linux-64::scikit-image==0.16.2=py36hb3f55d8_0\n",
      "  - conda-forge/noarch::seaborn==0.11.1=hd8ed1ab_1\n",
      "  - conda-forge/linux-64::jupyter==1.0.0=py36h5fab9bb_6\n",
      "  - conda-forge/noarch::odo==0.5.1=py_1\n",
      "  - conda-forge/linux-64::matplotlib==3.3.4=py36h5fab9bb_0\n",
      "  - conda-forge/linux-64::blaze==0.11.3=py36_0\n",
      "  - conda-forge/noarch::jupyterlab==3.0.9=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::dask==2021.2.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::anaconda-client==1.7.2=py_0\n",
      "  - conda-forge/noarch::anaconda-project==0.9.1=pyhd8ed1ab_0\n",
      "done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.4\n",
      "  latest version: 4.10.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ec2-user/anaconda3/envs/python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - xgboost\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _py-xgboost-mutex-2.0      |            cpu_0           8 KB  conda-forge\n",
      "    astroid-2.5.2              |   py36h5fab9bb_0         300 KB  conda-forge\n",
      "    botocore-1.19.52           |     pyhd8ed1ab_0         4.4 MB  conda-forge\n",
      "    dataclasses-0.8            |     pyh787bdff_0          22 KB  conda-forge\n",
      "    docutils-0.17              |   py36h5fab9bb_0         760 KB  conda-forge\n",
      "    flask-cors-3.0.8           |             py_0          14 KB  conda-forge\n",
      "    libxgboost-1.3.3           |       h9c3ff4c_2         3.3 MB  conda-forge\n",
      "    lxml-4.6.3                 |   py36h04a5ba7_0         1.5 MB  conda-forge\n",
      "    pillow-8.1.2               |   py36ha6010c0_1         691 KB  conda-forge\n",
      "    py-xgboost-1.3.3           |   py36h5fab9bb_2         124 KB  conda-forge\n",
      "    pylint-2.7.2               |   py36h5fab9bb_0         466 KB  conda-forge\n",
      "    xgboost-1.3.3              |   py36h5fab9bb_2          11 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        11.6 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _py-xgboost-mutex  conda-forge/linux-64::_py-xgboost-mutex-2.0-cpu_0\n",
      "  aiohttp            conda-forge/linux-64::aiohttp-3.7.4-py36h8f6f2f9_0\n",
      "  astroid            conda-forge/linux-64::astroid-2.5.2-py36h5fab9bb_0\n",
      "  botocore           conda-forge/noarch::botocore-1.19.52-pyhd8ed1ab_0\n",
      "  colorama           conda-forge/noarch::colorama-0.4.4-pyh9f0ad1d_0\n",
      "  dataclasses        conda-forge/noarch::dataclasses-0.8-pyh787bdff_0\n",
      "  docutils           conda-forge/linux-64::docutils-0.17-py36h5fab9bb_0\n",
      "  flask-cors         conda-forge/noarch::flask-cors-3.0.8-py_0\n",
      "  idna               conda-forge/noarch::idna-2.10-pyh9f0ad1d_0\n",
      "  jupyter_console    conda-forge/linux-64::jupyter_console-5.2.0-py36_1\n",
      "  libxgboost         conda-forge/linux-64::libxgboost-1.3.3-h9c3ff4c_2\n",
      "  lxml               conda-forge/linux-64::lxml-4.6.3-py36h04a5ba7_0\n",
      "  openjpeg           conda-forge/linux-64::openjpeg-2.4.0-hf7af979_0\n",
      "  pillow             conda-forge/linux-64::pillow-8.1.2-py36ha6010c0_1\n",
      "  py-xgboost         conda-forge/linux-64::py-xgboost-1.3.3-py36h5fab9bb_2\n",
      "  pylint             conda-forge/linux-64::pylint-2.7.2-py36h5fab9bb_0\n",
      "  requests           conda-forge/noarch::requests-2.25.1-pyhd3deb0d_0\n",
      "  urllib3            conda-forge/noarch::urllib3-1.26.4-pyhd8ed1ab_0\n",
      "  xgboost            conda-forge/linux-64::xgboost-1.3.3-py36h5fab9bb_2\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  openssl                                 1.1.1j-h7f98852_0 --> 1.1.1k-h7f98852_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "libxgboost-1.3.3     | 3.3 MB    | ##################################### | 100% \n",
      "astroid-2.5.2        | 300 KB    | ##################################### | 100% \n",
      "_py-xgboost-mutex-2. | 8 KB      | ##################################### | 100% \n",
      "flask-cors-3.0.8     | 14 KB     | ##################################### | 100% \n",
      "dataclasses-0.8      | 22 KB     | ##################################### | 100% \n",
      "docutils-0.17        | 760 KB    | ##################################### | 100% \n",
      "xgboost-1.3.3        | 11 KB     | ##################################### | 100% \n",
      "pylint-2.7.2         | 466 KB    | ##################################### | 100% \n",
      "lxml-4.6.3           | 1.5 MB    | ##################################### | 100% \n",
      "pillow-8.1.2         | 691 KB    | ##################################### | 100% \n",
      "botocore-1.19.52     | 4.4 MB    |                                       |   0% "
     ]
    }
   ],
   "source": [
    "!conda install -y -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "plt.rcdefaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alz_blood_all = pd.read_csv('alz_blood_all.csv', index_col=0,low_memory=False)\n",
    "#alz_blood_all = alz_blood_all.set_index('sample_id')\n",
    "alz_blood_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns with >10% NAs\n",
    "nas=alz_blood_all.isnull().sum()\n",
    "nas=nas[1:]\n",
    "        \n",
    "for i in nas:\n",
    "    if i>=len(alz_blood_all.index)/10:\n",
    "        try:\n",
    "            alz_blood_all=alz_blood_all.drop(nas.keys()[i], axis=1)\n",
    "        except KeyError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alz_blood_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to do test-train split with mean imputation\n",
    "#Index: ID, Col 0: AGE (no NAs), Col 1+: CpGs\n",
    "def mean_impute(data):\n",
    "    nas=data.isnull().sum()    \n",
    "    col_means=data.mean(axis=0)\n",
    "    na_cols=[]\n",
    "    na_cols_means=[]\n",
    "\n",
    "    for i in range(len(nas)):\n",
    "        if nas[i]!=0:        \n",
    "            na_cols.append(nas.keys()[i])\n",
    "            na_cols_means.append(col_means[i])\n",
    "        \n",
    "    ids=list(data.index)\n",
    "    for i in ids:\n",
    "        for j in range(len(na_cols)):\n",
    "            if str(data.loc[i][na_cols[j]])==\"nan\":\n",
    "                data.loc[i][na_cols[j]]=na_cols_means[j]\n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes df of importance scores produced by repeat_XGBoost and sorts by mean imp score\n",
    "def importances_sorted_by_mean(df_imp):\n",
    "    df_imp_sorted = df_imp.sort_values('Mean', ascending=False)\n",
    "    return df_imp_sorted\n",
    "\n",
    "# Makes a histogram of the frequecy of cgs in the top (top_num) importance scores\n",
    "def histogram_of_top_CpGs_by_importance(df_imp, top_num=20):\n",
    "    vs = []\n",
    "    inds = []\n",
    "    for col in df_imp.columns[:-2]:\n",
    "        c = df_imp[col].sort_values(ascending=False)\n",
    "        vs.append(c[:top_num])\n",
    "        inds  = inds + list(c.index[:top_num])\n",
    "    h = pd.Series(inds).value_counts()\n",
    "    # Plotting the first 100 importance scores\n",
    "    plt.figure(figsize = (30, 12))\n",
    "    plt.bar(h.index[:100],h[:100])\n",
    "    plt.title('Frequency of CpGs in the top 100 importances')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xlabel('CpG')\n",
    "    plt.xticks(fontsize = 16, rotation=90)\n",
    "    plt.show()\n",
    "    return inds, vs, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding cpgs with on average the highest importance scores, see mean columnn in df below\n",
    "#df_imp_sorted = importances_sorted_by_mean(df_imp)\n",
    "#df_imp_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function makes a histogram of the frequency of cpgs in the top 100 in the 50 trials above\n",
    "#inds, vs, h = histogram_of_top_CpGs_by_importance(df_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "mp.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 10\n",
      "Starting trial 11\n",
      "Starting trial 12\n",
      "Starting trial 13\n",
      "Starting trial 14\n",
      "Starting trial 15\n",
      "Starting trial 16\n",
      "Starting trial 17\n",
      "Starting trial 18\n",
      "Starting trial 19\n",
      "Starting trial 20\n",
      "Starting trial 21\n",
      "Starting trial 22\n",
      "Starting trial 23\n",
      "Starting trial 24\n",
      "Starting trial 25\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import _pickle as cPickle\n",
    "\n",
    "\n",
    "#Df=q\n",
    "def one_fit(X,y,test_size, i):\n",
    "    print('Starting trial ' + str(i))\n",
    "\n",
    "    X_tr, X_tst, y_train, y_test = train_test_split(X, y, test_size=test_size,random_state=i)\n",
    "    X_train = mean_impute(X_tr)\n",
    "    X_test = mean_impute(X_tst)\n",
    "\n",
    "    XG = XGBRegressor(objective='reg:squarederror',\n",
    "                n_estimators=200,\n",
    "                min_child_weight=1,\n",
    "                max_depth=3,\n",
    "                subsample=0.7,\n",
    "                colsample_bytree=0.5,\n",
    "                learning_rate=0.1)\n",
    "\n",
    "    eval_set = [(X_train, y_train),(X_test, y_test)]\n",
    "    XG.fit(X_train, y_train, eval_metric=\"rmse\", early_stopping_rounds = 10, eval_set=eval_set, verbose=False)\n",
    "\n",
    "    #preds_train = XG.predict(X_train)\n",
    "    #preds_test = XG.predict(X_test)\n",
    "    #rms_train.append((mean_squared_error(y_train, preds_train))**0.5)\n",
    "    #rms_test.append((mean_squared_error(y_test, preds_test))**0.5)\n",
    "    #r2_train.append(r2_score(y_train, preds_train))\n",
    "    #r2_test.append(r2_score(y_test, preds_test))\n",
    "    print('Ending trial ' + str(i))\n",
    "    file = 'xgb_imp_alz_blood_'+str(i)\n",
    "    with open(file, 'wb') as fp:\n",
    "        cPickle.dump(XG.feature_importances_, fp)\n",
    "        \n",
    "    return XG.feature_importances_\n",
    "\n",
    "def rep_xgb(df,iterations=50,test_size=0.25,early_stopping_rounds=10):\n",
    "\n",
    "    ncpu=mp.cpu_count()\n",
    "    X = df.iloc[:,1:]\n",
    "    y = df.iloc[:,0]\n",
    "    \n",
    "    pool = mp.Pool(ncpu)\n",
    "    results = [pool.apply_async(one_fit,    args=(X,y,test_size, i)) for i in [2,3,4,8,10,12,17,20,22,23,25,30,31,32,33,46,47,49]]\n",
    "    importances = [p.get() for p in results]\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    #df_imp = pd.DataFrame(importances, columns = df.columns[1:])\n",
    "    #df_imp = df_imp.transpose()\n",
    "    #cols = []\n",
    "    #for i in range(1,iterations+1):\n",
    "        #cols.append('trial_'+str(i))\n",
    "    #df_imp.columns = cols\n",
    "    #df_imp['Mean'] = df_imp.mean(axis=1)\n",
    "    #df_imp['Std'] = df_imp.std(axis=1)\n",
    "    \n",
    "    return importances\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = 'xgb_imp_park_blood_'+str(2)\n",
    "#with open(r\"xgb_imp_park_blood_2\", \"rb\") as input_file:\n",
    "    #trial = cPickle.load(input_file)\n",
    "#trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 0\n",
      "Starting trial 1\n",
      "Starting trial 2\n",
      "Starting trial 3\n",
      "Starting trial 4\n",
      "Starting trial 5\n",
      "Starting trial 6\n",
      "Starting trial 7\n",
      "Starting trial 8\n",
      "Starting trial 9\n",
      "Starting trial 10\n",
      "Starting trial 11\n",
      "Starting trial 12\n",
      "Starting trial 13\n",
      "Starting trial 14\n",
      "Starting trial 15\n",
      "Starting trial 16\n",
      "Starting trial 17\n",
      "Starting trial 18\n",
      "Starting trial 19\n",
      "Starting trial 20\n",
      "Starting trial 21\n",
      "Starting trial 22\n",
      "Starting trial 23\n",
      "Starting trial 24\n",
      "Starting trial 25\n",
      "Starting trial 26\n",
      "Starting trial 27\n",
      "Starting trial 28\n",
      "Starting trial 29\n",
      "Starting trial 30\n",
      "Starting trial 31\n",
      "Starting trial 32\n",
      "Starting trial 33\n",
      "Starting trial 34\n",
      "Starting trial 35\n",
      "Ending trial 13\n",
      "Starting trial 36\n",
      "Starting trial 37\n",
      "Ending trial 1\n",
      "Starting trial 38\n",
      "Ending trial 28\n",
      "Starting trial 39\n",
      "Ending trial 18\n",
      "Starting trial 40\n",
      "Ending trial 24\n",
      "Starting trial 41\n",
      "Ending trial 11\n",
      "Starting trial 42\n",
      "Ending trial 16\n",
      "Starting trial 43\n",
      "Ending trial 9\n",
      "Starting trial 44\n",
      "Starting trial 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-38:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "MemoryError\n",
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 405, in _handle_workers\n",
      "    pool._maintain_pool()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 246, in _maintain_pool\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 239, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/context.py\", line 277, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/popen_fork.py\", line 66, in _launch\n",
      "    self.pid = os.fork()\n",
      "OSError: [Errno 12] Cannot allocate memory\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 48\n",
      "Ending trial 27\n",
      "Ending trial 5\n",
      "Ending trial 0\n",
      "Ending trial 26\n",
      "Ending trial 21\n",
      "Ending trial 14\n",
      "Ending trial 7\n",
      "Ending trial 35\n",
      "Ending trial 15\n",
      "Ending trial 19\n",
      "Ending trial 29\n",
      "Ending trial 6\n",
      "Ending trial 34\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "imp_alz_blood_all=rep_xgb(alz_blood_all,iterations=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'xgb_imp_park_blood_all.csv'\n",
    "imp_park_blood_all.to_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_1</th>\n",
       "      <th>trial_2</th>\n",
       "      <th>trial_3</th>\n",
       "      <th>trial_4</th>\n",
       "      <th>trial_5</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cg00050873</th>\n",
       "      <td>0.036211</td>\n",
       "      <td>0.036595</td>\n",
       "      <td>0.018020</td>\n",
       "      <td>0.047033</td>\n",
       "      <td>0.024760</td>\n",
       "      <td>0.032524</td>\n",
       "      <td>0.010113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg00212031</th>\n",
       "      <td>0.048078</td>\n",
       "      <td>0.046578</td>\n",
       "      <td>0.059213</td>\n",
       "      <td>0.040443</td>\n",
       "      <td>0.059545</td>\n",
       "      <td>0.050771</td>\n",
       "      <td>0.007480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg00213748</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049529</td>\n",
       "      <td>0.009906</td>\n",
       "      <td>0.019812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg00214611</th>\n",
       "      <td>0.045916</td>\n",
       "      <td>0.063088</td>\n",
       "      <td>0.033133</td>\n",
       "      <td>0.043157</td>\n",
       "      <td>0.056335</td>\n",
       "      <td>0.048326</td>\n",
       "      <td>0.010444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg00455876</th>\n",
       "      <td>0.036821</td>\n",
       "      <td>0.038455</td>\n",
       "      <td>0.040642</td>\n",
       "      <td>0.041370</td>\n",
       "      <td>0.043483</td>\n",
       "      <td>0.040154</td>\n",
       "      <td>0.002315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg01707559</th>\n",
       "      <td>0.044100</td>\n",
       "      <td>0.060216</td>\n",
       "      <td>0.058890</td>\n",
       "      <td>0.060506</td>\n",
       "      <td>0.047639</td>\n",
       "      <td>0.054270</td>\n",
       "      <td>0.006971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg02004872</th>\n",
       "      <td>0.044332</td>\n",
       "      <td>0.038084</td>\n",
       "      <td>0.053020</td>\n",
       "      <td>0.044935</td>\n",
       "      <td>0.038704</td>\n",
       "      <td>0.043815</td>\n",
       "      <td>0.005389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg02011394</th>\n",
       "      <td>0.048895</td>\n",
       "      <td>0.043364</td>\n",
       "      <td>0.049808</td>\n",
       "      <td>0.058596</td>\n",
       "      <td>0.048873</td>\n",
       "      <td>0.049907</td>\n",
       "      <td>0.004908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg02050847</th>\n",
       "      <td>0.056570</td>\n",
       "      <td>0.037465</td>\n",
       "      <td>0.062141</td>\n",
       "      <td>0.049514</td>\n",
       "      <td>0.061134</td>\n",
       "      <td>0.053365</td>\n",
       "      <td>0.009114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg02233190</th>\n",
       "      <td>0.044017</td>\n",
       "      <td>0.053667</td>\n",
       "      <td>0.093656</td>\n",
       "      <td>0.050950</td>\n",
       "      <td>0.041726</td>\n",
       "      <td>0.056803</td>\n",
       "      <td>0.018937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg02494853</th>\n",
       "      <td>0.080720</td>\n",
       "      <td>0.081924</td>\n",
       "      <td>0.068265</td>\n",
       "      <td>0.069499</td>\n",
       "      <td>0.072112</td>\n",
       "      <td>0.074504</td>\n",
       "      <td>0.005717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg02839557</th>\n",
       "      <td>0.045119</td>\n",
       "      <td>0.063874</td>\n",
       "      <td>0.044983</td>\n",
       "      <td>0.035689</td>\n",
       "      <td>0.040654</td>\n",
       "      <td>0.046064</td>\n",
       "      <td>0.009552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg02842889</th>\n",
       "      <td>0.050444</td>\n",
       "      <td>0.055067</td>\n",
       "      <td>0.068608</td>\n",
       "      <td>0.057610</td>\n",
       "      <td>0.056646</td>\n",
       "      <td>0.057675</td>\n",
       "      <td>0.005995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg03052502</th>\n",
       "      <td>0.083754</td>\n",
       "      <td>0.039725</td>\n",
       "      <td>0.043742</td>\n",
       "      <td>0.052344</td>\n",
       "      <td>0.059596</td>\n",
       "      <td>0.055832</td>\n",
       "      <td>0.015567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg03155755</th>\n",
       "      <td>0.058470</td>\n",
       "      <td>0.055599</td>\n",
       "      <td>0.049628</td>\n",
       "      <td>0.066919</td>\n",
       "      <td>0.066711</td>\n",
       "      <td>0.059465</td>\n",
       "      <td>0.006645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg03244189</th>\n",
       "      <td>0.099457</td>\n",
       "      <td>0.100822</td>\n",
       "      <td>0.078946</td>\n",
       "      <td>0.085766</td>\n",
       "      <td>0.062724</td>\n",
       "      <td>0.085543</td>\n",
       "      <td>0.014081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg03443143</th>\n",
       "      <td>0.064227</td>\n",
       "      <td>0.073322</td>\n",
       "      <td>0.070596</td>\n",
       "      <td>0.058297</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>0.065208</td>\n",
       "      <td>0.005917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg03683899</th>\n",
       "      <td>0.059287</td>\n",
       "      <td>0.063829</td>\n",
       "      <td>0.056584</td>\n",
       "      <td>0.073728</td>\n",
       "      <td>0.058813</td>\n",
       "      <td>0.062448</td>\n",
       "      <td>0.006111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg03695421</th>\n",
       "      <td>0.053580</td>\n",
       "      <td>0.048326</td>\n",
       "      <td>0.050126</td>\n",
       "      <td>0.063643</td>\n",
       "      <td>0.051417</td>\n",
       "      <td>0.053418</td>\n",
       "      <td>0.005392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             trial_1   trial_2   trial_3   trial_4   trial_5      Mean  \\\n",
       "cg00050873  0.036211  0.036595  0.018020  0.047033  0.024760  0.032524   \n",
       "cg00212031  0.048078  0.046578  0.059213  0.040443  0.059545  0.050771   \n",
       "cg00213748  0.000000  0.000000  0.000000  0.000000  0.049529  0.009906   \n",
       "cg00214611  0.045916  0.063088  0.033133  0.043157  0.056335  0.048326   \n",
       "cg00455876  0.036821  0.038455  0.040642  0.041370  0.043483  0.040154   \n",
       "cg01707559  0.044100  0.060216  0.058890  0.060506  0.047639  0.054270   \n",
       "cg02004872  0.044332  0.038084  0.053020  0.044935  0.038704  0.043815   \n",
       "cg02011394  0.048895  0.043364  0.049808  0.058596  0.048873  0.049907   \n",
       "cg02050847  0.056570  0.037465  0.062141  0.049514  0.061134  0.053365   \n",
       "cg02233190  0.044017  0.053667  0.093656  0.050950  0.041726  0.056803   \n",
       "cg02494853  0.080720  0.081924  0.068265  0.069499  0.072112  0.074504   \n",
       "cg02839557  0.045119  0.063874  0.044983  0.035689  0.040654  0.046064   \n",
       "cg02842889  0.050444  0.055067  0.068608  0.057610  0.056646  0.057675   \n",
       "cg03052502  0.083754  0.039725  0.043742  0.052344  0.059596  0.055832   \n",
       "cg03155755  0.058470  0.055599  0.049628  0.066919  0.066711  0.059465   \n",
       "cg03244189  0.099457  0.100822  0.078946  0.085766  0.062724  0.085543   \n",
       "cg03443143  0.064227  0.073322  0.070596  0.058297  0.059600  0.065208   \n",
       "cg03683899  0.059287  0.063829  0.056584  0.073728  0.058813  0.062448   \n",
       "cg03695421  0.053580  0.048326  0.050126  0.063643  0.051417  0.053418   \n",
       "\n",
       "                 Std  \n",
       "cg00050873  0.010113  \n",
       "cg00212031  0.007480  \n",
       "cg00213748  0.019812  \n",
       "cg00214611  0.010444  \n",
       "cg00455876  0.002315  \n",
       "cg01707559  0.006971  \n",
       "cg02004872  0.005389  \n",
       "cg02011394  0.004908  \n",
       "cg02050847  0.009114  \n",
       "cg02233190  0.018937  \n",
       "cg02494853  0.005717  \n",
       "cg02839557  0.009552  \n",
       "cg02842889  0.005995  \n",
       "cg03052502  0.015567  \n",
       "cg03155755  0.006645  \n",
       "cg03244189  0.014081  \n",
       "cg03443143  0.005917  \n",
       "cg03683899  0.006111  \n",
       "cg03695421  0.005392  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_park_blood_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
